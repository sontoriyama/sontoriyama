# Hi there! I'm Son-Goku-Coder (@sontoriyama) ðŸ‘‹

### Full Stack Engineer & Open Source Contributor
**High-Performance Architecture & AI Integration Specialist**

ðŸš€ **From a passionate self-taught developer to a contributor in major AI projects.**
I have been breaking barriers in web and software development for over 4 years, evolving from the classic MERN stack towards complex low-latency architectures, Edge systems, and AI Agents.

---

### ðŸ† Recent Achievement: Big Tech Contributor (Alibaba Cloud)

A dream come true! I have officially participated in the development of the **QwenLM** ecosystem, one of the most powerful LLMs in the world.

*   **The Context:** I contributed to `qwen-code` (Qwen-Agent). It is worth noting that **`qwen-cli` is architecturally inspired by Google's `gemini-cli`**, demonstrating that I am working with code standards adopted by major tech giants.
*   **The Contribution:** I implemented critical logic for the **Model Context Protocol (MCP)** integration, fixing gaps in the agent instructions.
*   **The Background:** This wasn't just a copy-paste job. I achieved this by deep-diving into advanced Agentic AI and MCP concepts (special dedication to my self-study marathons with *AI Anytime* courses) to truly understand how to give LLMs "superpowers" via tools.

ðŸ”— **[See my accepted Pull Request: Advanced Logic for MCP Integration](https://github.com/QwenLM/qwen-code/pull/796)**

---

### ðŸ”­ Current Project: "Hyper-Voice" Chrome Extension (Experimental)

I am building an experimental next-gen browser extension with integrated **ASR (Automatic Speech Recognition)** and **TTS (Text-to-Speech)** to free developers from the keyboard and prioritize physical health.

*   **Architecture:** Backend running on **Bun** with native WebSockets to achieve *sub-millisecond* latency.
*   **Extreme Performance:** Implementation of memory piping with 16kb buffers to handle real-time audio streaming without touching the disk, effectively avoiding Garbage Collector blocking.
*   **The Challenge:** Overcoming **Manifest V3** limitations by utilizing *Offscreen* documents for persistent and smooth audio processing.

---

### ðŸ›  Tech Stack & Arsenal

I don't limit myself to a single framework; I choose the tool that makes the code fly.

*   **Core:** JavaScript (ESNext), TypeScript, **Bun** (Current favorite for speed).
*   **Frontend:** Next.js, React, Astro (for static/content-heavy sites), TailwindCSS.
*   **Backend & Runtime:** Node.js, **Bun** (Native WebSockets), Express, Trpc.
*   **Data & State:** MongoDB, PostgreSQL (Prisma), In-Memory File Systems (Streams/Buffers).
*   **AI & ML Engineering:** Integration of LLMs (Gemini, Qwen), **MCP** implementation, Whisper (ASR), TTS pipelines, WebGL/Three.js visualizations.
*   **Mobile:** React Native (Android/iOS).

---

### ðŸ“œ My Story

I started 4 years ago studying day and night (kudos to the community: Midu, Fazt). My philosophy is *Mobile First* and extreme optimization. I have gone from building e-commerce layouts to designing systems that process real-time audio and collaborating on the codebase of global AI models.

> "I don't just want it to work, I want it to fly. If I have to go down to the level of buffers and streams to optimize, that's where you'll find me."

---

### ðŸ“« Connect with me

I am open to collaborations on Open Source projects, AI integrations (especially Agents and MCP), or complex web architecture challenges.

*   ðŸ“§ **Email:** songokumbl@gmail.com
*   ðŸ’» **GitHub:** [sontoriyama](https://github.com/sontoriyama)

<!--
Proud contributor to QwenLM ecosystem
-->
